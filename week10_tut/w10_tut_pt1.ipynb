{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Tutorial Part 1 Solved\n",
    "\n",
    "Part 1 covers:\n",
    "\n",
    "* Importing data of multiple portfolios and preparing it for regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "When we introduced this material in week09, we performed the CAPM test using individual stocks (like the original Fama & MacBeth 1973 paper). Now, we are going to use portfolios instead of individual stocks - make sure you know why this improves the reliability of the test.\n",
    "\n",
    "We are going to use 100 value-weighted test portfolios formed by sorting first by size (into 10 deciles) and then by book-to-market (10 deciles inside each size decile) constructed at annual frequency and available from the Ken French data website \n",
    "(https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_100_port_sz.html)\n",
    "You can read the full details of how the portfolios are constructed by following the link.\n",
    "\n",
    "The market risk premium and the T-bill rate are on monthly basis and all data is in percentage points (we should divide by 100 if we prefer decimal representation) covering the period July 1926 - Sept 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a csv file of the prices on the stocks and save it as a panda series\n",
    "import pandas as pd\n",
    "rets = pd.read_csv(\"ff_100_size_bm_port_monthly.csv\", index_col=0)\n",
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a csv file of the market risk premium and risk-free rate\n",
    "data = pd.read_csv(\"ff_factors_monthly.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Make sure headers are the same accross the two dataframes.\n",
    "\n",
    "All we need to do is form excess returns on the portfolios. Everything is already in returns, Rf is monthly and the MRP is computed for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P500 index\n",
    "ex_rets = rets.sub(data['rf'],axis=0)\n",
    "ex_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data\n",
    "\n",
    "Export the prepared data in a single csv file to use in the Stata kernel for the regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MRP as a column at the start of ex_rets\n",
    "data_stata = pd.concat([data.ex_mkt,ex_rets],axis=1)\n",
    "data_stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data as a csv file for Stata\n",
    "data_stata.to_csv('data_stata.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can now download the data file to your own machine if you wish but we shall use it directly from this folder in the Stata kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
